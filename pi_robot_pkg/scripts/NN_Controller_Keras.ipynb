{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN Controller - Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-nmW0O5OXmW",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ITxNcd-eeg",
        "colab_type": "code",
        "outputId": "7b86b3be-83da-41e5-fd6f-69252a988b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from keras.models import load_model\n",
        "import yaml\n",
        "import glob\n",
        "from keras.models import Model\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3isrTIj-OkLg",
        "colab_type": "text"
      },
      "source": [
        "# Get Data\n",
        "Data is obtained by concatenating all the csv files obtained from simulation using PID controllers. The collect_data.py script is used to generate these csv files during simulation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW8Mazpc_C0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    PATH = '/content/drive/My Drive/Neural Network Controller/data/'\n",
        "    files = glob.glob(f'{PATH}*.csv')[:]\n",
        "    print(files)\n",
        "    df = pd.concat([pd.read_csv(f) for f in files])\n",
        "    print(df.head())\n",
        "    df = df.drop(['id'], axis = 1)\n",
        "    X = df.drop(['target'], axis = 1)\n",
        "    Y = pd.DataFrame(df['target'])\n",
        "    return X.values, Y.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kFTbJf_J3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(X, Y):\n",
        "#     X, Y = shuffle(X, Y)\n",
        "    length = X.shape[0]\n",
        "    split = int(length * 0.9)\n",
        "    X_train = X[:split]\n",
        "    Y_train = Y[:split]\n",
        "    X_test = X[split:]\n",
        "    Y_test = Y[split:]\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHW0oU5y_F1n",
        "colab_type": "code",
        "outputId": "332503fb-5b22-47db-fe3a-e3cc7e5461fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "X, Y = get_data()\n",
        "X_train, Y_train, X_test, Y_test = split_data(X, Y)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/Neural Network Controller/data/data1.csv', '/content/drive/My Drive/Neural Network Controller/data/data2.csv', '/content/drive/My Drive/Neural Network Controller/data/data3.csv']\n",
            "   id       cur_pos       cur_vel         error  goal_pos        target\n",
            "0   0 -4.882628e-10 -2.338387e-09  4.882628e-10       0.0  9.813957e-06\n",
            "1   1  4.883240e-10  2.454111e-09 -4.883240e-10       0.0 -9.815358e-06\n",
            "2   2 -4.834622e-10  1.027551e-08  4.834622e-10       0.0  5.470557e-08\n",
            "3   3  4.877077e-10  3.308846e-09 -4.877077e-10       0.0 -9.801325e-06\n",
            "4   4  4.882628e-10  2.537998e-09 -4.882628e-10       0.0 -9.813948e-06\n",
            "(25678, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnF-uvfUO039",
        "colab_type": "text"
      },
      "source": [
        "# Build and Compile Model\n",
        "\n",
        "The model is 4 layers with relu activation function for each layer except the last one. Since the task is regression, the final layer activation function is linear. \n",
        "\n",
        "The mean absolute error is used as loss as mean squared error tends to give undesirable weightage to outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yki0YMl_fuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, kernel_initializer = 'normal', activation = 'relu', input_shape = (4,)))\n",
        "  model.add(Dense(256, kernel_initializer = 'normal', activation = 'relu'))\n",
        "  model.add(Dense(256, kernel_initializer = 'normal', activation = 'relu'))\n",
        "  model.add(Dense(1, kernel_initializer = 'normal', activation = 'linear'))\n",
        "  model.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics = ['mse', 'mae'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7utgWPIBARQ5",
        "colab_type": "code",
        "outputId": "0da5b05a-41c2-440a-c20e-c874bb780e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "model = get_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 128)               640       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 99,713\n",
            "Trainable params: 99,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPhl1uqbO8Ak",
        "colab_type": "text"
      },
      "source": [
        "# Train Model\n",
        " \n",
        " Model is trained for 200 epochs with batch size of 16. After training, the model is saved to be retrieved later to extract the weights and store them in a format that can be easily read in C++"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqOz96_wCmOr",
        "colab_type": "code",
        "outputId": "d270ecb7-601d-4ef3-9236-09b262ad38a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size = 16, epochs = 200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 6.0691 - mean_squared_error: 22118.7148 - mean_absolute_error: 6.0691\n",
            "Epoch 2/200\n",
            "25678/25678 [==============================] - 4s 169us/step - loss: 5.3107 - mean_squared_error: 22034.4637 - mean_absolute_error: 5.3107\n",
            "Epoch 3/200\n",
            "25678/25678 [==============================] - 4s 172us/step - loss: 5.2723 - mean_squared_error: 21990.8823 - mean_absolute_error: 5.2723\n",
            "Epoch 4/200\n",
            "25678/25678 [==============================] - 4s 171us/step - loss: 5.2502 - mean_squared_error: 21968.7257 - mean_absolute_error: 5.2502\n",
            "Epoch 5/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 5.2158 - mean_squared_error: 21959.3829 - mean_absolute_error: 5.2158\n",
            "Epoch 6/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 5.2095 - mean_squared_error: 21946.5563 - mean_absolute_error: 5.2095\n",
            "Epoch 7/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 5.1962 - mean_squared_error: 21951.8567 - mean_absolute_error: 5.1962\n",
            "Epoch 8/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 5.1826 - mean_squared_error: 21950.2037 - mean_absolute_error: 5.1826\n",
            "Epoch 9/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 5.1815 - mean_squared_error: 21950.5922 - mean_absolute_error: 5.1815\n",
            "Epoch 10/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 5.1691 - mean_squared_error: 21953.2380 - mean_absolute_error: 5.1691\n",
            "Epoch 11/200\n",
            "25678/25678 [==============================] - 4s 171us/step - loss: 5.1671 - mean_squared_error: 21935.4195 - mean_absolute_error: 5.1671\n",
            "Epoch 12/200\n",
            "25678/25678 [==============================] - 4s 171us/step - loss: 5.1644 - mean_squared_error: 21943.9137 - mean_absolute_error: 5.1644\n",
            "Epoch 13/200\n",
            "25678/25678 [==============================] - 5s 175us/step - loss: 5.1522 - mean_squared_error: 21940.4358 - mean_absolute_error: 5.1522\n",
            "Epoch 14/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 5.1552 - mean_squared_error: 21936.0037 - mean_absolute_error: 5.1552\n",
            "Epoch 15/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 5.1541 - mean_squared_error: 21932.9653 - mean_absolute_error: 5.1541\n",
            "Epoch 16/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 5.1371 - mean_squared_error: 21936.2339 - mean_absolute_error: 5.1371\n",
            "Epoch 17/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 5.1385 - mean_squared_error: 21936.5906 - mean_absolute_error: 5.1385\n",
            "Epoch 18/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 5.1328 - mean_squared_error: 21923.2733 - mean_absolute_error: 5.1328\n",
            "Epoch 19/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 5.1317 - mean_squared_error: 21904.3891 - mean_absolute_error: 5.1317\n",
            "Epoch 20/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 5.1214 - mean_squared_error: 21908.7684 - mean_absolute_error: 5.1214\n",
            "Epoch 21/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 5.1200 - mean_squared_error: 21905.2934 - mean_absolute_error: 5.1200\n",
            "Epoch 22/200\n",
            "25678/25678 [==============================] - 5s 175us/step - loss: 5.1212 - mean_squared_error: 21884.5864 - mean_absolute_error: 5.1212\n",
            "Epoch 23/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 5.1230 - mean_squared_error: 21893.8965 - mean_absolute_error: 5.1230\n",
            "Epoch 24/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 5.1180 - mean_squared_error: 21871.0216 - mean_absolute_error: 5.1180\n",
            "Epoch 25/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 5.1127 - mean_squared_error: 21835.6992 - mean_absolute_error: 5.1127\n",
            "Epoch 26/200\n",
            "25678/25678 [==============================] - 4s 170us/step - loss: 5.1094 - mean_squared_error: 21833.8750 - mean_absolute_error: 5.1094\n",
            "Epoch 27/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 5.1124 - mean_squared_error: 21816.2133 - mean_absolute_error: 5.1124\n",
            "Epoch 28/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 5.1107 - mean_squared_error: 21780.7395 - mean_absolute_error: 5.1107\n",
            "Epoch 29/200\n",
            "25678/25678 [==============================] - 4s 170us/step - loss: 5.1155 - mean_squared_error: 21749.8033 - mean_absolute_error: 5.1155\n",
            "Epoch 30/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 5.0963 - mean_squared_error: 21721.3126 - mean_absolute_error: 5.0963\n",
            "Epoch 31/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 5.0989 - mean_squared_error: 21676.6560 - mean_absolute_error: 5.0989\n",
            "Epoch 32/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 5.0995 - mean_squared_error: 21626.8931 - mean_absolute_error: 5.0995\n",
            "Epoch 33/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 5.0979 - mean_squared_error: 21597.1412 - mean_absolute_error: 5.0979\n",
            "Epoch 34/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 5.0923 - mean_squared_error: 21546.3709 - mean_absolute_error: 5.0923\n",
            "Epoch 35/200\n",
            "25678/25678 [==============================] - 5s 188us/step - loss: 5.0930 - mean_squared_error: 21455.7314 - mean_absolute_error: 5.0930\n",
            "Epoch 36/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 5.0887 - mean_squared_error: 21441.5327 - mean_absolute_error: 5.0887\n",
            "Epoch 37/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 5.0966 - mean_squared_error: 21254.4070 - mean_absolute_error: 5.0966\n",
            "Epoch 38/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 5.0852 - mean_squared_error: 21257.0843 - mean_absolute_error: 5.0852\n",
            "Epoch 39/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 5.0767 - mean_squared_error: 21140.1001 - mean_absolute_error: 5.0767\n",
            "Epoch 40/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 5.0712 - mean_squared_error: 21070.5472 - mean_absolute_error: 5.0712\n",
            "Epoch 41/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 5.0695 - mean_squared_error: 20785.4562 - mean_absolute_error: 5.0695\n",
            "Epoch 42/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 5.0660 - mean_squared_error: 20695.5597 - mean_absolute_error: 5.0660\n",
            "Epoch 43/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 5.0582 - mean_squared_error: 20322.8980 - mean_absolute_error: 5.0582\n",
            "Epoch 44/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 5.0549 - mean_squared_error: 20050.5614 - mean_absolute_error: 5.0549\n",
            "Epoch 45/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 5.0289 - mean_squared_error: 19527.5617 - mean_absolute_error: 5.0289\n",
            "Epoch 46/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 5.0348 - mean_squared_error: 18552.1293 - mean_absolute_error: 5.0348\n",
            "Epoch 47/200\n",
            "25678/25678 [==============================] - 5s 190us/step - loss: 4.9995 - mean_squared_error: 18284.8341 - mean_absolute_error: 4.9995\n",
            "Epoch 48/200\n",
            "25678/25678 [==============================] - 5s 188us/step - loss: 4.9978 - mean_squared_error: 16979.1492 - mean_absolute_error: 4.9978\n",
            "Epoch 49/200\n",
            "25678/25678 [==============================] - 5s 186us/step - loss: 4.9732 - mean_squared_error: 16687.8325 - mean_absolute_error: 4.9732\n",
            "Epoch 50/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.9450 - mean_squared_error: 15078.3564 - mean_absolute_error: 4.9450\n",
            "Epoch 51/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.8677 - mean_squared_error: 14013.4836 - mean_absolute_error: 4.8677\n",
            "Epoch 52/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.8700 - mean_squared_error: 12695.2594 - mean_absolute_error: 4.8700\n",
            "Epoch 53/200\n",
            "25678/25678 [==============================] - 5s 196us/step - loss: 4.7954 - mean_squared_error: 10809.4924 - mean_absolute_error: 4.7954\n",
            "Epoch 54/200\n",
            "25678/25678 [==============================] - 5s 198us/step - loss: 4.7009 - mean_squared_error: 10221.2365 - mean_absolute_error: 4.7009\n",
            "Epoch 55/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.6846 - mean_squared_error: 7806.8129 - mean_absolute_error: 4.6846\n",
            "Epoch 56/200\n",
            "25678/25678 [==============================] - 5s 184us/step - loss: 4.5493 - mean_squared_error: 7294.6083 - mean_absolute_error: 4.5493\n",
            "Epoch 57/200\n",
            "25678/25678 [==============================] - 5s 187us/step - loss: 4.4946 - mean_squared_error: 6666.5607 - mean_absolute_error: 4.4946\n",
            "Epoch 58/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 4.3786 - mean_squared_error: 6489.2817 - mean_absolute_error: 4.3786\n",
            "Epoch 59/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.4580 - mean_squared_error: 6944.2793 - mean_absolute_error: 4.4580\n",
            "Epoch 60/200\n",
            "25678/25678 [==============================] - 5s 194us/step - loss: 4.4092 - mean_squared_error: 6592.8735 - mean_absolute_error: 4.4092\n",
            "Epoch 61/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.4453 - mean_squared_error: 6828.5310 - mean_absolute_error: 4.4453\n",
            "Epoch 62/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.3872 - mean_squared_error: 6512.4534 - mean_absolute_error: 4.3872\n",
            "Epoch 63/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.4766 - mean_squared_error: 7074.5556 - mean_absolute_error: 4.4766\n",
            "Epoch 64/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3541 - mean_squared_error: 6415.0810 - mean_absolute_error: 4.3541\n",
            "Epoch 65/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.5010 - mean_squared_error: 7367.2699 - mean_absolute_error: 4.5010\n",
            "Epoch 66/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 4.3771 - mean_squared_error: 6427.3096 - mean_absolute_error: 4.3771\n",
            "Epoch 67/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 4.4596 - mean_squared_error: 6989.0019 - mean_absolute_error: 4.4596\n",
            "Epoch 68/200\n",
            "25678/25678 [==============================] - 5s 190us/step - loss: 4.3781 - mean_squared_error: 6507.7667 - mean_absolute_error: 4.3781\n",
            "Epoch 69/200\n",
            "25678/25678 [==============================] - 5s 195us/step - loss: 4.4898 - mean_squared_error: 7216.0556 - mean_absolute_error: 4.4898\n",
            "Epoch 70/200\n",
            "25678/25678 [==============================] - 5s 190us/step - loss: 4.3667 - mean_squared_error: 6481.2865 - mean_absolute_error: 4.3667\n",
            "Epoch 71/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.4444 - mean_squared_error: 6810.8127 - mean_absolute_error: 4.4444\n",
            "Epoch 72/200\n",
            "25678/25678 [==============================] - 5s 184us/step - loss: 4.4234 - mean_squared_error: 6752.6962 - mean_absolute_error: 4.4234\n",
            "Epoch 73/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 4.3689 - mean_squared_error: 6490.3566 - mean_absolute_error: 4.3689\n",
            "Epoch 74/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.4723 - mean_squared_error: 7112.7330 - mean_absolute_error: 4.4723\n",
            "Epoch 75/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 4.3390 - mean_squared_error: 6407.5611 - mean_absolute_error: 4.3390\n",
            "Epoch 76/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 4.4820 - mean_squared_error: 7218.3445 - mean_absolute_error: 4.4820\n",
            "Epoch 77/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3192 - mean_squared_error: 6373.9364 - mean_absolute_error: 4.3192\n",
            "Epoch 78/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 4.5084 - mean_squared_error: 7461.3310 - mean_absolute_error: 4.5084\n",
            "Epoch 79/200\n",
            "25678/25678 [==============================] - 4s 170us/step - loss: 4.3339 - mean_squared_error: 6375.6228 - mean_absolute_error: 4.3339\n",
            "Epoch 80/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.5063 - mean_squared_error: 7379.0885 - mean_absolute_error: 4.5063\n",
            "Epoch 81/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.3594 - mean_squared_error: 6457.8232 - mean_absolute_error: 4.3594\n",
            "Epoch 82/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 4.4799 - mean_squared_error: 7191.7976 - mean_absolute_error: 4.4799\n",
            "Epoch 83/200\n",
            "25678/25678 [==============================] - 5s 192us/step - loss: 4.3562 - mean_squared_error: 6455.3463 - mean_absolute_error: 4.3562\n",
            "Epoch 84/200\n",
            "25678/25678 [==============================] - 5s 189us/step - loss: 4.4776 - mean_squared_error: 7143.1363 - mean_absolute_error: 4.4776\n",
            "Epoch 85/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.3897 - mean_squared_error: 6583.0641 - mean_absolute_error: 4.3897\n",
            "Epoch 86/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.4483 - mean_squared_error: 6952.0061 - mean_absolute_error: 4.4483\n",
            "Epoch 87/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.3674 - mean_squared_error: 6489.3378 - mean_absolute_error: 4.3674\n",
            "Epoch 88/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.4456 - mean_squared_error: 6790.9024 - mean_absolute_error: 4.4456\n",
            "Epoch 89/200\n",
            "25678/25678 [==============================] - 5s 186us/step - loss: 4.4128 - mean_squared_error: 6730.1468 - mean_absolute_error: 4.4128\n",
            "Epoch 90/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 4.3907 - mean_squared_error: 6588.3425 - mean_absolute_error: 4.3907\n",
            "Epoch 91/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.4404 - mean_squared_error: 6931.6684 - mean_absolute_error: 4.4404\n",
            "Epoch 92/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.3402 - mean_squared_error: 6428.8011 - mean_absolute_error: 4.3402\n",
            "Epoch 93/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 4.4623 - mean_squared_error: 7122.8797 - mean_absolute_error: 4.4623\n",
            "Epoch 94/200\n",
            "25678/25678 [==============================] - 5s 186us/step - loss: 4.3535 - mean_squared_error: 6446.2193 - mean_absolute_error: 4.3535\n",
            "Epoch 95/200\n",
            "25678/25678 [==============================] - 5s 187us/step - loss: 4.4542 - mean_squared_error: 7045.6009 - mean_absolute_error: 4.4542\n",
            "Epoch 96/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.3702 - mean_squared_error: 6502.2118 - mean_absolute_error: 4.3702\n",
            "Epoch 97/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.4554 - mean_squared_error: 7060.3606 - mean_absolute_error: 4.4554\n",
            "Epoch 98/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.3229 - mean_squared_error: 6388.0353 - mean_absolute_error: 4.3229\n",
            "Epoch 99/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.4791 - mean_squared_error: 7266.2043 - mean_absolute_error: 4.4791\n",
            "Epoch 100/200\n",
            "25678/25678 [==============================] - 4s 172us/step - loss: 4.3099 - mean_squared_error: 6372.4665 - mean_absolute_error: 4.3099\n",
            "Epoch 101/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.4924 - mean_squared_error: 7398.6185 - mean_absolute_error: 4.4924\n",
            "Epoch 102/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.3250 - mean_squared_error: 6388.3637 - mean_absolute_error: 4.3250\n",
            "Epoch 103/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.4704 - mean_squared_error: 7233.6631 - mean_absolute_error: 4.4704\n",
            "Epoch 104/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.3280 - mean_squared_error: 6400.0933 - mean_absolute_error: 4.3280\n",
            "Epoch 105/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.4835 - mean_squared_error: 7310.5267 - mean_absolute_error: 4.4835\n",
            "Epoch 106/200\n",
            "25678/25678 [==============================] - 4s 170us/step - loss: 4.3033 - mean_squared_error: 6373.3696 - mean_absolute_error: 4.3033\n",
            "Epoch 107/200\n",
            "25678/25678 [==============================] - 5s 175us/step - loss: 4.4802 - mean_squared_error: 7313.6944 - mean_absolute_error: 4.4802\n",
            "Epoch 108/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.2963 - mean_squared_error: 6364.7239 - mean_absolute_error: 4.2963\n",
            "Epoch 109/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.5568 - mean_squared_error: 8184.3143 - mean_absolute_error: 4.5568\n",
            "Epoch 110/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.3268 - mean_squared_error: 6384.1214 - mean_absolute_error: 4.3268\n",
            "Epoch 111/200\n",
            "25678/25678 [==============================] - 5s 175us/step - loss: 4.4810 - mean_squared_error: 7316.2329 - mean_absolute_error: 4.4810\n",
            "Epoch 112/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3654 - mean_squared_error: 6510.0223 - mean_absolute_error: 4.3654\n",
            "Epoch 113/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3873 - mean_squared_error: 6619.3970 - mean_absolute_error: 4.3873\n",
            "Epoch 114/200\n",
            "25678/25678 [==============================] - 5s 186us/step - loss: 4.4281 - mean_squared_error: 6871.5290 - mean_absolute_error: 4.4281\n",
            "Epoch 115/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3843 - mean_squared_error: 6597.4642 - mean_absolute_error: 4.3843\n",
            "Epoch 116/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.4235 - mean_squared_error: 6822.2591 - mean_absolute_error: 4.4235\n",
            "Epoch 117/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 4.3449 - mean_squared_error: 6449.8595 - mean_absolute_error: 4.3449\n",
            "Epoch 118/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.4735 - mean_squared_error: 7240.7917 - mean_absolute_error: 4.4735\n",
            "Epoch 119/200\n",
            "25678/25678 [==============================] - 5s 193us/step - loss: 4.3042 - mean_squared_error: 6370.8451 - mean_absolute_error: 4.3042\n",
            "Epoch 120/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.4949 - mean_squared_error: 7466.0512 - mean_absolute_error: 4.4949\n",
            "Epoch 121/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.3090 - mean_squared_error: 6368.9969 - mean_absolute_error: 4.3090\n",
            "Epoch 122/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 4.5040 - mean_squared_error: 7570.9214 - mean_absolute_error: 4.5040\n",
            "Epoch 123/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.3261 - mean_squared_error: 6406.5191 - mean_absolute_error: 4.3261\n",
            "Epoch 124/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 4.5149 - mean_squared_error: 7664.7571 - mean_absolute_error: 4.5149\n",
            "Epoch 125/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.3057 - mean_squared_error: 6374.1008 - mean_absolute_error: 4.3057\n",
            "Epoch 126/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.5169 - mean_squared_error: 7701.0995 - mean_absolute_error: 4.5169\n",
            "Epoch 127/200\n",
            "25678/25678 [==============================] - 5s 184us/step - loss: 4.3310 - mean_squared_error: 6407.7155 - mean_absolute_error: 4.3310\n",
            "Epoch 128/200\n",
            "25678/25678 [==============================] - 5s 184us/step - loss: 4.4609 - mean_squared_error: 7172.1392 - mean_absolute_error: 4.4609\n",
            "Epoch 129/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 4.3498 - mean_squared_error: 6472.8523 - mean_absolute_error: 4.3498\n",
            "Epoch 130/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.4440 - mean_squared_error: 7016.7433 - mean_absolute_error: 4.4440\n",
            "Epoch 131/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3827 - mean_squared_error: 6625.3435 - mean_absolute_error: 4.3827\n",
            "Epoch 132/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 4.3672 - mean_squared_error: 6543.0447 - mean_absolute_error: 4.3672\n",
            "Epoch 133/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.4106 - mean_squared_error: 6802.2349 - mean_absolute_error: 4.4106\n",
            "Epoch 134/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.3813 - mean_squared_error: 6582.0632 - mean_absolute_error: 4.3813\n",
            "Epoch 135/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 4.4335 - mean_squared_error: 6950.8892 - mean_absolute_error: 4.4335\n",
            "Epoch 136/200\n",
            "25678/25678 [==============================] - 5s 184us/step - loss: 4.3427 - mean_squared_error: 6451.1112 - mean_absolute_error: 4.3427\n",
            "Epoch 137/200\n",
            "25678/25678 [==============================] - 5s 186us/step - loss: 4.4476 - mean_squared_error: 7082.2237 - mean_absolute_error: 4.4476\n",
            "Epoch 138/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.2989 - mean_squared_error: 6367.1687 - mean_absolute_error: 4.2989\n",
            "Epoch 139/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.4806 - mean_squared_error: 7358.2787 - mean_absolute_error: 4.4806\n",
            "Epoch 140/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3227 - mean_squared_error: 6384.4770 - mean_absolute_error: 4.3227\n",
            "Epoch 141/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.4792 - mean_squared_error: 7220.4548 - mean_absolute_error: 4.4792\n",
            "Epoch 142/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.3463 - mean_squared_error: 6478.3277 - mean_absolute_error: 4.3463\n",
            "Epoch 143/200\n",
            "25678/25678 [==============================] - 5s 182us/step - loss: 4.4361 - mean_squared_error: 6998.8894 - mean_absolute_error: 4.4361\n",
            "Epoch 144/200\n",
            "25678/25678 [==============================] - 5s 186us/step - loss: 4.3471 - mean_squared_error: 6480.0430 - mean_absolute_error: 4.3471\n",
            "Epoch 145/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.4260 - mean_squared_error: 6892.8285 - mean_absolute_error: 4.4260\n",
            "Epoch 146/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 4.3927 - mean_squared_error: 6700.6342 - mean_absolute_error: 4.3927\n",
            "Epoch 147/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.3894 - mean_squared_error: 6662.3355 - mean_absolute_error: 4.3894\n",
            "Epoch 148/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 4.4032 - mean_squared_error: 6748.1427 - mean_absolute_error: 4.4032\n",
            "Epoch 149/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.3608 - mean_squared_error: 6511.9520 - mean_absolute_error: 4.3608\n",
            "Epoch 150/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 4.4409 - mean_squared_error: 7058.2136 - mean_absolute_error: 4.4409\n",
            "Epoch 151/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.3071 - mean_squared_error: 6369.2891 - mean_absolute_error: 4.3071\n",
            "Epoch 152/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.4875 - mean_squared_error: 7476.1698 - mean_absolute_error: 4.4875\n",
            "Epoch 153/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.3122 - mean_squared_error: 6387.0014 - mean_absolute_error: 4.3122\n",
            "Epoch 154/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.4956 - mean_squared_error: 7524.8823 - mean_absolute_error: 4.4956\n",
            "Epoch 155/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 4.3378 - mean_squared_error: 6454.8030 - mean_absolute_error: 4.3378\n",
            "Epoch 156/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 4.4532 - mean_squared_error: 7159.0231 - mean_absolute_error: 4.4532\n",
            "Epoch 157/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 4.3247 - mean_squared_error: 6412.4979 - mean_absolute_error: 4.3247\n",
            "Epoch 158/200\n",
            "25678/25678 [==============================] - 4s 171us/step - loss: 4.4522 - mean_squared_error: 7080.6626 - mean_absolute_error: 4.4522\n",
            "Epoch 159/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.3439 - mean_squared_error: 6467.7008 - mean_absolute_error: 4.3439\n",
            "Epoch 160/200\n",
            "25678/25678 [==============================] - 4s 173us/step - loss: 4.4091 - mean_squared_error: 6807.9475 - mean_absolute_error: 4.4091\n",
            "Epoch 161/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.3984 - mean_squared_error: 6725.6256 - mean_absolute_error: 4.3984\n",
            "Epoch 162/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.3734 - mean_squared_error: 6579.9441 - mean_absolute_error: 4.3734\n",
            "Epoch 163/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.4121 - mean_squared_error: 6812.6251 - mean_absolute_error: 4.4121\n",
            "Epoch 164/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.3633 - mean_squared_error: 6542.1627 - mean_absolute_error: 4.3633\n",
            "Epoch 165/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.4416 - mean_squared_error: 7038.3926 - mean_absolute_error: 4.4416\n",
            "Epoch 166/200\n",
            "25678/25678 [==============================] - 5s 175us/step - loss: 4.3160 - mean_squared_error: 6396.1833 - mean_absolute_error: 4.3160\n",
            "Epoch 167/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.4591 - mean_squared_error: 7183.2985 - mean_absolute_error: 4.4591\n",
            "Epoch 168/200\n",
            "25678/25678 [==============================] - 4s 172us/step - loss: 4.2948 - mean_squared_error: 6356.6416 - mean_absolute_error: 4.2948\n",
            "Epoch 169/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.4922 - mean_squared_error: 7533.0606 - mean_absolute_error: 4.4922\n",
            "Epoch 170/200\n",
            "25678/25678 [==============================] - 4s 170us/step - loss: 4.3448 - mean_squared_error: 6420.1843 - mean_absolute_error: 4.3448\n",
            "Epoch 171/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.4815 - mean_squared_error: 7429.4684 - mean_absolute_error: 4.4815\n",
            "Epoch 172/200\n",
            "25678/25678 [==============================] - 5s 186us/step - loss: 4.3337 - mean_squared_error: 6437.7240 - mean_absolute_error: 4.3337\n",
            "Epoch 173/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.4619 - mean_squared_error: 7235.0142 - mean_absolute_error: 4.4619\n",
            "Epoch 174/200\n",
            "25678/25678 [==============================] - 5s 184us/step - loss: 4.3475 - mean_squared_error: 6435.4514 - mean_absolute_error: 4.3475\n",
            "Epoch 175/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.4265 - mean_squared_error: 6915.1158 - mean_absolute_error: 4.4265\n",
            "Epoch 176/200\n",
            "25678/25678 [==============================] - 5s 181us/step - loss: 4.3588 - mean_squared_error: 6520.6215 - mean_absolute_error: 4.3588\n",
            "Epoch 177/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.4227 - mean_squared_error: 6877.8099 - mean_absolute_error: 4.4227\n",
            "Epoch 178/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.3851 - mean_squared_error: 6667.6980 - mean_absolute_error: 4.3851\n",
            "Epoch 179/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.3835 - mean_squared_error: 6644.5546 - mean_absolute_error: 4.3835\n",
            "Epoch 180/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.4037 - mean_squared_error: 6759.7867 - mean_absolute_error: 4.4037\n",
            "Epoch 181/200\n",
            "25678/25678 [==============================] - 5s 185us/step - loss: 4.3910 - mean_squared_error: 6672.5153 - mean_absolute_error: 4.3910\n",
            "Epoch 182/200\n",
            "25678/25678 [==============================] - 5s 178us/step - loss: 4.4077 - mean_squared_error: 6811.4507 - mean_absolute_error: 4.4077\n",
            "Epoch 183/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.3556 - mean_squared_error: 6512.6214 - mean_absolute_error: 4.3556\n",
            "Epoch 184/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.3939 - mean_squared_error: 6720.7224 - mean_absolute_error: 4.3939\n",
            "Epoch 185/200\n",
            "25678/25678 [==============================] - 4s 175us/step - loss: 4.3936 - mean_squared_error: 6706.9258 - mean_absolute_error: 4.3936\n",
            "Epoch 186/200\n",
            "25678/25678 [==============================] - 4s 171us/step - loss: 4.4009 - mean_squared_error: 6763.1409 - mean_absolute_error: 4.4009\n",
            "Epoch 187/200\n",
            "25678/25678 [==============================] - 4s 174us/step - loss: 4.3431 - mean_squared_error: 6467.1398 - mean_absolute_error: 4.3431\n",
            "Epoch 188/200\n",
            "25678/25678 [==============================] - 5s 195us/step - loss: 4.4379 - mean_squared_error: 7034.9173 - mean_absolute_error: 4.4379\n",
            "Epoch 189/200\n",
            "25678/25678 [==============================] - 5s 193us/step - loss: 4.3112 - mean_squared_error: 6376.9963 - mean_absolute_error: 4.3112\n",
            "Epoch 190/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 4.4654 - mean_squared_error: 7308.4952 - mean_absolute_error: 4.4654\n",
            "Epoch 191/200\n",
            "25678/25678 [==============================] - 5s 179us/step - loss: 4.3027 - mean_squared_error: 6360.4281 - mean_absolute_error: 4.3027\n",
            "Epoch 192/200\n",
            "25678/25678 [==============================] - 5s 183us/step - loss: 4.5262 - mean_squared_error: 7946.8393 - mean_absolute_error: 4.5262\n",
            "Epoch 193/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.2745 - mean_squared_error: 6338.6109 - mean_absolute_error: 4.2745\n",
            "Epoch 194/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.4775 - mean_squared_error: 7430.6387 - mean_absolute_error: 4.4775\n",
            "Epoch 195/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.2914 - mean_squared_error: 6347.2500 - mean_absolute_error: 4.2914\n",
            "Epoch 196/200\n",
            "25678/25678 [==============================] - 5s 176us/step - loss: 4.4485 - mean_squared_error: 7142.1175 - mean_absolute_error: 4.4485\n",
            "Epoch 197/200\n",
            "25678/25678 [==============================] - 5s 187us/step - loss: 4.3312 - mean_squared_error: 6420.5356 - mean_absolute_error: 4.3312\n",
            "Epoch 198/200\n",
            "25678/25678 [==============================] - 5s 177us/step - loss: 4.4217 - mean_squared_error: 6899.5890 - mean_absolute_error: 4.4217\n",
            "Epoch 199/200\n",
            "25678/25678 [==============================] - 5s 175us/step - loss: 4.3548 - mean_squared_error: 6511.6425 - mean_absolute_error: 4.3548\n",
            "Epoch 200/200\n",
            "25678/25678 [==============================] - 5s 180us/step - loss: 4.4281 - mean_squared_error: 6944.8007 - mean_absolute_error: 4.4281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23ad496860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzTEEuFuFwqF",
        "colab_type": "code",
        "outputId": "1ab7c3f3-c7a4-46fb-fd6a-7d4b5f3a77b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.evaluate(X_test, Y_test)\n",
        "model.save('/content/drive/My Drive/Neural Network Controller/models tensorflow/model_2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2854/2854 [==============================] - 0s 72us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TbG37PVFRyX",
        "colab_type": "code",
        "outputId": "df9c0505-af43-4b23-eae9-3d2873fd721f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Neural Network Controller/models tensorflow/model_2.h5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 128)               640       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 99,713\n",
            "Trainable params: 99,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X0uv9J-QkTE",
        "colab_type": "text"
      },
      "source": [
        "# Extract trained model weights to file\n",
        "\n",
        "Since the weights are stored as h5 files, reading them directly in C++ is nontrivial. To simplify this I iterate over the layers in the trained model, extract the weights, biases and activation functions and store them in a text file that can be easily processed by the controller plugin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEOBOo58Hh-r",
        "colab_type": "code",
        "outputId": "451f7946-0132-46f7-98a1-ba15bb183796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "with open('/content/drive/My Drive/Neural Network Controller/models tensorflow/weights_3.txt', 'w') as file:\n",
        "  params = {}\n",
        "  file.write(str(len(model.layers)))\n",
        "  file.write('\\n')\n",
        "  for i, layer in enumerate(model.layers):\n",
        "    weights = layer.get_weights()\n",
        "    config = layer.get_config()\n",
        "    weights[1] = weights[1].reshape((1, weights[1].shape[0]))\n",
        "    params['W' + str(i + 1)] = weights[0]\n",
        "    params['b' + str(i + 1)] = weights[1]\n",
        "    file.write('W' + str(i + 1))\n",
        "    file.write('\\n')\n",
        "    file.write(' '.join('%s' % x for x in weights[0].shape))\n",
        "    file.write('\\n')\n",
        "    file.write(config['activation'])\n",
        "    file.write('\\n')\n",
        "    weights[0].tofile(file, sep=\" \", format=\"%s\")\n",
        "    print(weights[0].shape)\n",
        "    file.write('\\n')\n",
        "    file.write('b' + str(i + 1))\n",
        "    file.write('\\n')\n",
        "    file.write(' '.join('%s' % x for x in weights[1].shape))\n",
        "    file.write('\\n')\n",
        "    weights[1].tofile(file, sep=\" \", format=\"%s\")\n",
        "    file.write('\\n')\n",
        "    print(weights[1].shape)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 128)\n",
            "(1, 128)\n",
            "(128, 256)\n",
            "(1, 256)\n",
            "(256, 256)\n",
            "(1, 256)\n",
            "(256, 1)\n",
            "(1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyCUxhDNQKKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(params['W1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rjayhbjEVbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_name = 'dense_11'\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "intermediate_output = intermediate_layer_model.predict(x)\n",
        "print(intermediate_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}